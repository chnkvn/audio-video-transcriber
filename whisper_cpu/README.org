#+TITLE: WHISPER-CPU
#+Description: A local implementation of (distil) whisper, with the aim to be run by any computer.

* Roadmap
- Gradio
- Docker
* Transcript
** Code
:properties:
:header-args:python: :tangle app.py
:end:
#+begin_src python
import tempfile
import time
from pathlib import Path
from typing import Tuple, Union

import torch
import yt_dlp as youtube_dl
from attrs import define
from faster_whisper import WhisperModel

import gradio as gr

# Variables
FILE_LIMIT_MB = 1000
YT_LENGTH_LIMIT_S = 3600
AVAILABLE_LANGUAGES = ["English", "French", "Multilingual"]


# Model
@define
class Model:
    language: str = "en"
    _model: Union[WhisperModel, None] = None

    @property
    def model(self) -> WhisperModel:
        """Initialize a model depending on the language.
        - en : Initialize faster-distil-whisper-large-v2
        - fr : Initialize whisper-large-v3-french-distil-dec16
        - multi : Initialize whisper-large-v2. Slower results.
        NB : whisper-large-v3 is prone to hallucinate more often
        than whisper-large-v2.
        """
        if not self._model:
            if self.language == "fr":
                model_path = (
                    "../models/whisper-large-v3-french-distil-dec16/ctranslate2"
                )
            elif self.language == "multi":
                model_path = "../models/faster-whisper-large-v2"
            else:  # english
                self.language = 'en'
                model_path = "../models/faster-distil-whisper-large-v2"
            # Initialize model
            device = "cuda" if torch.cuda.is_available() else "cpu"
            compute_type_dict = {"cuda": "float16", "cpu": "int8"}
            self._model = WhisperModel(
                model_path,
                device=device,
                compute_type=compute_type_dict[device],
            )
        return self._model

    def transcribe_media(
        self,
        mediapath: Union[str, Path],
    ) -> Tuple[str, str]:
        """Transcribe a media using model
        - Generate a version with timestamps
        - Generate another version without timestamps
        """
        if mediapath.startswith("https://"):
            mediapath = download_yt_audio(mediapath)
        segments, info = self.model.transcribe(
            mediapath,
            beam_size=5,
            # language=self.language
            condition_on_previous_text=False,
        )
        transcript = ""
        no_ts_transcript = ""
        for segment in segments:
            formatted_segment = "[%.2fs -> %.2fs] %s" % (
                segment.start,
                segment.end,
                segment.text,
            )
            transcript += formatted_segment + "\n"
            no_ts_transcript += segment.text.strip() + "\n"
        return transcript, no_ts_transcript


# Download a youtube video
def download_yt_audio(yt_url) -> str:
    """
    Download a video using its url.
    Return a string describing the path of the downloaded media.
    """
    info_loader = youtube_dl.YoutubeDL()
    Path("..", "dl").mkdir(parents=True, exist_ok=True)
    try:
        info = info_loader.extract_info(yt_url, download=False)
        filename = str(Path("..", "dl", f"{info['title']}.mp4"))
    except youtube_dl.utils.DownloadError as err:
        raise gr.Error(str(err))

    file_length = info["duration_string"]
    file_h_m_s = file_length.split(":")
    file_h_m_s = [int(sub_length) for sub_length in file_h_m_s]

    if len(file_h_m_s) == 1:
        file_h_m_s.insert(0, 0)
    if len(file_h_m_s) == 2:
        file_h_m_s.insert(0, 0)
    file_length_s = file_h_m_s[0] * 3600 + file_h_m_s[1] * 60 + file_h_m_s[2]

    if file_length_s > YT_LENGTH_LIMIT_S:
        yt_length_limit_hms = time.strftime(
            "%HH:%MM:%SS", time.gmtime(YT_LENGTH_LIMIT_S)
        )
        file_length_hms = time.strftime("%HH:%MM:%SS", time.gmtime(file_length_s))
        raise gr.Error(
            f"Maximum YouTube length is {yt_length_limit_hms},"
            f" got {file_length_hms} YouTube video."
        )
    ydl_opts = {
        "outtmpl": filename,
        "format": "worstvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
    }

    with youtube_dl.YoutubeDL(ydl_opts) as ydl:
        try:
            ydl.download([yt_url])
            return filename
        except youtube_dl.utils.ExtractorError as err:
            raise gr.Error(err(str))


# Define function to save output to a file
def save_output_to_file(output_text, suffix=".txt") -> str:
    with tempfile.NamedTemporaryFile(
        delete=False, mode="w", suffix=suffix
    ) as temp_file:
        temp_file.write(output_text)
        return temp_file.name


# Process
def main(language: str, media: Union[str, Path]) -> Tuple[str, str, str, str]:
    """
    Choose a language to load a model
    eventually download the media and transcribe it,
    with and without timestamps.
    Save them in two distinct temporary files.
    Return the transcripts, and the files containing the transcripts.
    """

    models_dict = {
        "French": Model(language="fr"),
        "English": Model(),
        "Multilingual": Model(language="multi"),
    }
    # Choose the model according to language choice
    model = models_dict.get(language, models_dict["English"])
    # Transcribe media
    transcript, no_ts_transcript = model.transcribe_media(media)
    # Create temporary files containing the transcripts.
    transcript_file = save_output_to_file(transcript, ".srt")
    no_ts_transcript_file = save_output_to_file(no_ts_transcript)
    return transcript, no_ts_transcript, transcript_file, no_ts_transcript_file


# Interface
def run_app():
    gr.close_all()
    demo = gr.Blocks(title="Media transcriber")
    # Youtube tab
    yt = gr.Interface(
        fn=main,
        inputs=[
            gr.Radio(
                AVAILABLE_LANGUAGES,
                label="language",
                value="English",
                info="If possible, opt for the Engligh or the French model. "
                "The multilingual model is a model "
                "that works more slowly than others.",
            ),
            gr.Textbox(
                label="media",
                value="https://youtu.be/XrZPLF0ezw8",
            ),
        ],
        outputs=[
            gr.Textbox(label="transcript without timestamps"),
            gr.Textbox(label="transcript with timestamps"),
            gr.DownloadButton(label="Download transcript with timestamps"),
            gr.DownloadButton(label="Download transcript without timestamps"),
        ],
        title="Transcribe YouTube videos using Distill-whisper",
        description=(
            "Transcribe long-form YouTube videos with the click of a button! "
            "The model may have a hard time with background sounds/voices "
            "and proper nouns, so check the results!"
        ),
        allow_flagging="never",
    )
    # Local file
    local_file = gr.Interface(
        fn=main,
        inputs=[
            gr.Radio(
                AVAILABLE_LANGUAGES,
                label="language",
                value="English",
                info="If possible, opt for the Engligh or the French model. "
                "The multilingual model is a model "
                "that works more slowly than others.",
            ),
            gr.File(label="media", file_types=["audio", "video"]),
        ],
        outputs=[
            gr.Textbox(label="transcript with timestamps"),
            gr.Textbox(label="transcript without timestamps"),
            gr.DownloadButton(label="Download transcript with timestamps"),
            gr.DownloadButton(label="Download transcript without timestamps"),
        ],
        title="Transcribe a local audio file using Distill-whisper",
        description=(
            "Transcribe a local audio file with the click of a button! "
            "The model may have a hard time with background sounds/voices "
            "and proper nouns, so check the results!"
        ),
        allow_flagging="never",
    )
    # Combine tabs
    with demo:
        gr.TabbedInterface(
            [yt, local_file], ["Youtube transcriber", "Local file transcriber"]
        )
    demo.launch()


if __name__ == "__main__":
    run_app()
#+end_src
* Unit tests
** Code
:properties:
:header-args:python: :tangle ../tests/tests.py
:end:
#+begin_src python
import unittest

from whisper_cpu.transcript import Model, main


class TestModel(unittest.TestCase):
    def test_en(self):
        test_file_en = "test_en.mp3"
        test_transcript, no_ts_test_transcript, file_tr, no_file_tr = main(
            "English", test_file_en
        )
        self.assertIn(
            "Today, in the world of freedom, the proudest boast is", test_transcript
        )
        self.assertIn(
            "Today, in the world of freedom, the proudest boast is",
            no_ts_test_transcript,
        )
        with open(file_tr, "r") as f_tr:
            self.assertEqual(f_tr.read(), test_transcript)
        with open(no_file_tr, "r") as f_no_tr:
            self.assertEqual(f_no_tr.read(), no_ts_test_transcript)

    def test_fr(self):
        test_file_en = "test_fr.ogg"
        test_transcript, no_ts_test_transcript, file_tr, no_file_tr = main(
            "French", test_file_en
        )
        self.assertIn("La goutte d'eau qui fait déborder le vase", test_transcript)
        self.assertIn(
            "La goutte d'eau qui fait déborder le vase",
            no_ts_test_transcript,
        )
        with open(file_tr, "r") as f_tr:
            self.assertEqual(f_tr.read(), test_transcript)
        with open(no_file_tr, "r") as f_no_tr:
            self.assertEqual(f_no_tr.read(), no_ts_test_transcript)

    def test_multi(self):
        test_file_en = "test_en.mp3"
        test_transcript, no_ts_test_transcript, file_tr, no_file_tr = main(
            "Multilingual", test_file_en
        )
        self.assertIn(
            "Today, in the world of freedom, the proudest boast is", test_transcript
        )
        self.assertIn(
            "Today, in the world of freedom, the proudest boast is",
            no_ts_test_transcript,
        )
        self.assertIn("Ich bin ein ", test_transcript)
        self.assertIn(
            "Ich bin ein ",
            no_ts_test_transcript,
        )
        with open(file_tr, "r") as f_tr:
            self.assertEqual(f_tr.read(), test_transcript)
        with open(no_file_tr, "r") as f_no_tr:
            self.assertEqual(f_no_tr.read(), no_ts_test_transcript)

    def test_invalid_language(self):
        test_file_en = "test_en.mp3"
        test_transcript, no_ts_test_transcript, file_tr, no_file_tr = main(
            "Dummy", test_file_en
        )

        self.assertIn(
            "Today, in the world of freedom, the proudest boast is", test_transcript
        )
        self.assertIn(
            "Today, in the world of freedom, the proudest boast is",
            no_ts_test_transcript,
        )
        with open(file_tr, "r") as f_tr:
            self.assertEqual(f_tr.read(), test_transcript)
        with open(no_file_tr, "r") as f_no_tr:
            self.assertEqual(f_no_tr.read(), no_ts_test_transcript)
        dummy_model = Model("Dummy")
        self.assertEqual(dummy_model.language, "Dummy")
        dummy_model.model
        self.assertEqual(dummy_model.language, "en")


if __name__ == "__main__":
    unittest.main()
#+end_src
